# Modernizing Nuclear Physics Data Processing

| Presenter | Date | Slides | Code | Repo |
|:---------:|:----:|:------:|:----:|:----:|
| Stan Paulauskas | 2019-05-19 | [slides](paulauskas-knoxdata-2019-05-17) | [Rmd](data-science-ish-presentation.Rmd) | [repo for `dolosse`](https://github.com/dolosse/dolosse) |

## Abstract

Experimental nuclear physics projects can collect terabytes of data over the course of an experiment. Detectors count rates range from a few to millions of counts per second. Data varies from log files to binary data to JSON. The current generation of acquisition and analysis frameworks cannot cope with increasing demands. The frameworks scale vertically, bigger better computers, with more RAM. This is the opposite of big data paradigms, which scale horizontally. We'll take a look at current frameworks, draw parallels to industry standards and how we can create a modern acquisition and analysis platform.

Check the `dolosse` repo for ongoing work to manage nucelar data from DAQs.

## About Speaker

Stanley Paulauskas, PhD, PMP is a professional data analyst and project manager. He has been working in data analytics since 2009. He received his Doctorate in Nuclear Physics in 2013. He became a registered Project Management Professional in 2015. He is a member of the East Tennessee PMI Chapter.

Stanley has authored and co-authored many publications in professional journals (NIMA, PRC, PRL). He specializes in data acquisition, analysis, and visualization using C++ and Python.